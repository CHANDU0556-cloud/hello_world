{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"spam_detector.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMBMptzTvWdfKKYn2jZSn3S"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"rjx2vEPBTpHo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"08e84def-ba9b-4b49-fbfc-8628758e3615","executionInfo":{"status":"ok","timestamp":1580620278219,"user_tz":-330,"elapsed":1216,"user":{"displayName":"chandra mohan rawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDutMpxlwi1FVhJZFlXcFNeM_4jIhRg2u8JTdcOgQ=s64","userId":"11308919128317599349"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MKV-A9nmTp_J","colab_type":"code","colab":{}},"source":["import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fk64WKgZT8Mi","colab_type":"code","colab":{}},"source":["mail=pd.read_csv('/content/drive/My Drive/docs/scan/AI/SMSSpamCollection.txt', sep='\\t',names=[\"label\",\"message\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QOXSQ0_kUnpp","colab_type":"code","colab":{}},"source":["import re"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IrV4XI7FUx_9","colab_type":"code","colab":{}},"source":["import nltk"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"afaZFXJNVGYD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"16a967de-8c4c-482b-824c-128a26cc3cd5","executionInfo":{"status":"ok","timestamp":1580620806181,"user_tz":-330,"elapsed":191026,"user":{"displayName":"chandra mohan rawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDutMpxlwi1FVhJZFlXcFNeM_4jIhRg2u8JTdcOgQ=s64","userId":"11308919128317599349"}}},"source":["nltk.download()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["NLTK Downloader\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n","Downloader> d\n","\n","Download which package (l=list; x=cancel)?\n","  Identifier> 1\n","    Error loading 1: Package '1' not found in index\n","\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n","Downloader> d\n","\n","Download which package (l=list; x=cancel)?\n","  Identifier> l\n","Packages:\n","  [ ] abc................. Australian Broadcasting Commission 2006\n","  [ ] alpino.............. Alpino Dutch Treebank\n","  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n","  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n","  [ ] basque_grammars..... Grammars for Basque\n","  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n","                           Extraction Systems in Biology)\n","  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n","  [ ] book_grammars....... Grammars from NLTK Book\n","  [ ] brown............... Brown Corpus\n","  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n","  [ ] cess_cat............ CESS-CAT Treebank\n","  [ ] cess_esp............ CESS-ESP Treebank\n","  [ ] chat80.............. Chat-80 Data Files\n","  [ ] city_database....... City Database\n","  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n","  [ ] comparative_sentences Comparative Sentence Dataset\n","  [ ] comtrans............ ComTrans Corpus Sample\n","  [ ] conll2000........... CONLL 2000 Chunking Corpus\n","  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n","Hit Enter to continue: \n","  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n","                           and Basque Subset)\n","  [ ] crubadan............ Crubadan Corpus\n","  [ ] dependency_treebank. Dependency Parsed Treebank\n","  [ ] dolch............... Dolch Word List\n","  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n","                           Corpus\n","  [ ] floresta............ Portuguese Treebank\n","  [ ] framenet_v15........ FrameNet 1.5\n","  [ ] framenet_v17........ FrameNet 1.7\n","  [ ] gazetteers.......... Gazeteer Lists\n","  [ ] genesis............. Genesis Corpus\n","  [ ] gutenberg........... Project Gutenberg Selections\n","  [ ] ieer................ NIST IE-ER DATA SAMPLE\n","  [ ] inaugural........... C-Span Inaugural Address Corpus\n","  [ ] indian.............. Indian Language POS-Tagged Corpus\n","  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n","                           ChaSen format)\n","  [ ] kimmo............... PC-KIMMO Data Files\n","  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n","  [ ] large_grammars...... Large context-free and feature-based grammars\n","                           for parser comparison\n","Hit Enter to continue: \n","  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n","  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n","                           part-of-speech tags\n","  [ ] machado............. Machado de Assis -- Obra Completa\n","  [ ] masc_tagged......... MASC Tagged Corpus\n","  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n","  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n","  [ ] moses_sample........ Moses Sample Models\n","  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n","  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n","  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n","                           2015) subset of the Paraphrase Database.\n","  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n","  [ ] nombank.1.0......... NomBank Corpus 1.0\n","  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n","  [ ] nps_chat............ NPS Chat\n","  [ ] omw................. Open Multilingual Wordnet\n","  [ ] opinion_lexicon..... Opinion Lexicon\n","  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n","  [ ] paradigms........... Paradigm Corpus\n","  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n","                           Evaluation Shared Task\n","Hit Enter to continue: \n","  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n","                           character properties in Perl\n","  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n","  [ ] pl196x.............. Polish language of the XX century sixties\n","  [ ] porter_test......... Porter Stemmer Test Files\n","  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n","  [ ] problem_reports..... Problem Report Corpus\n","  [ ] product_reviews_1... Product Reviews (5 Products)\n","  [ ] product_reviews_2... Product Reviews (9 Products)\n","  [ ] propbank............ Proposition Bank Corpus 1.0\n","  [ ] pros_cons........... Pros and Cons\n","  [ ] ptb................. Penn Treebank\n","  [ ] punkt............... Punkt Tokenizer Models\n","  [ ] qc.................. Experimental Data for Question Classification\n","  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n","                           version\n","  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n","                           Portuguesa)\n","  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n","  [ ] sample_grammars..... Sample Grammars\n","  [ ] semcor.............. SemCor 3.0\n","Hit Enter to continue: \n","  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n","  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n","  [ ] sentiwordnet........ SentiWordNet\n","  [ ] shakespeare......... Shakespeare XML Corpus Sample\n","  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n","  [ ] smultron............ SMULTRON Corpus Sample\n","  [ ] snowball_data....... Snowball Data\n","  [ ] spanish_grammars.... Grammars for Spanish\n","  [ ] state_union......... C-Span State of the Union Address Corpus\n","  [ ] subjectivity........ Subjectivity Dataset v1.0\n","  [ ] swadesh............. Swadesh Wordlists\n","  [ ] switchboard......... Switchboard Corpus Sample\n","  [ ] tagsets............. Help on Tagsets\n","  [ ] timit............... TIMIT Corpus Sample\n","  [ ] toolbox............. Toolbox Sample Files\n","  [ ] treebank............ Penn Treebank Sample\n","  [ ] twitter_samples..... Twitter Samples\n","  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n","                           (Unicode Version)\n","  [ ] udhr................ Universal Declaration of Human Rights Corpus\n","  [ ] unicode_samples..... Unicode Samples\n","Hit Enter to continue: \n","  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n","  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n","  [ ] vader_lexicon....... VADER Sentiment Lexicon\n","  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n","  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n","  [ ] webtext............. Web Text Corpus\n","  [ ] wmt15_eval.......... Evaluation data from WMT15\n","  [ ] word2vec_sample..... Word2Vec Sample\n","  [ ] wordnet............. WordNet\n","  [ ] wordnet_ic.......... WordNet-InfoContent\n","  [ ] words............... Word Lists\n","  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n","                           English Prose\n","\n","Collections:\n","  [P] all-corpora......... All the corpora\n","  [P] all-nltk............ All packages available on nltk_data gh-pages\n","                           branch\n","  [P] all................. All packages\n","  [P] book................ Everything used in the NLTK Book\n","  [P] popular............. Popular packages\n","  [ ] tests............... Packages for running tests\n","Hit Enter to continue: \n","  [ ] third-party......... Third-party data packages\n","\n","([*] marks installed packages; [P] marks partially installed collections)\n","\n","Download which package (l=list; x=cancel)?\n","  Identifier> l\n","Packages:\n","  [ ] abc................. Australian Broadcasting Commission 2006\n","  [ ] alpino.............. Alpino Dutch Treebank\n","  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n","  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n","  [ ] basque_grammars..... Grammars for Basque\n","  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n","                           Extraction Systems in Biology)\n","  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n","  [ ] book_grammars....... Grammars from NLTK Book\n","  [ ] brown............... Brown Corpus\n","  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n","  [ ] cess_cat............ CESS-CAT Treebank\n","  [ ] cess_esp............ CESS-ESP Treebank\n","  [ ] chat80.............. Chat-80 Data Files\n","  [ ] city_database....... City Database\n","  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n","  [ ] comparative_sentences Comparative Sentence Dataset\n","  [ ] comtrans............ ComTrans Corpus Sample\n","  [ ] conll2000........... CONLL 2000 Chunking Corpus\n","  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n","Hit Enter to continue: \n","  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n","                           and Basque Subset)\n","  [ ] crubadan............ Crubadan Corpus\n","  [ ] dependency_treebank. Dependency Parsed Treebank\n","  [ ] dolch............... Dolch Word List\n","  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n","                           Corpus\n","  [ ] floresta............ Portuguese Treebank\n","  [ ] framenet_v15........ FrameNet 1.5\n","  [ ] framenet_v17........ FrameNet 1.7\n","  [ ] gazetteers.......... Gazeteer Lists\n","  [ ] genesis............. Genesis Corpus\n","  [ ] gutenberg........... Project Gutenberg Selections\n","  [ ] ieer................ NIST IE-ER DATA SAMPLE\n","  [ ] inaugural........... C-Span Inaugural Address Corpus\n","  [ ] indian.............. Indian Language POS-Tagged Corpus\n","  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n","                           ChaSen format)\n","  [ ] kimmo............... PC-KIMMO Data Files\n","  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n","  [ ] large_grammars...... Large context-free and feature-based grammars\n","                           for parser comparison\n","Hit Enter to continue: \n","  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n","  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n","                           part-of-speech tags\n","  [ ] machado............. Machado de Assis -- Obra Completa\n","  [ ] masc_tagged......... MASC Tagged Corpus\n","  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n","  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n","  [ ] moses_sample........ Moses Sample Models\n","  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n","  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n","  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n","                           2015) subset of the Paraphrase Database.\n","  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n","  [ ] nombank.1.0......... NomBank Corpus 1.0\n","  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n","  [ ] nps_chat............ NPS Chat\n","  [ ] omw................. Open Multilingual Wordnet\n","  [ ] opinion_lexicon..... Opinion Lexicon\n","  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n","  [ ] paradigms........... Paradigm Corpus\n","  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n","                           Evaluation Shared Task\n","Hit Enter to continue: \n","  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n","                           character properties in Perl\n","  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n","  [ ] pl196x.............. Polish language of the XX century sixties\n","  [ ] porter_test......... Porter Stemmer Test Files\n","  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n","  [ ] problem_reports..... Problem Report Corpus\n","  [ ] product_reviews_1... Product Reviews (5 Products)\n","  [ ] product_reviews_2... Product Reviews (9 Products)\n","  [ ] propbank............ Proposition Bank Corpus 1.0\n","  [ ] pros_cons........... Pros and Cons\n","  [ ] ptb................. Penn Treebank\n","  [ ] punkt............... Punkt Tokenizer Models\n","  [ ] qc.................. Experimental Data for Question Classification\n","  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n","                           version\n","  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n","                           Portuguesa)\n","  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n","  [ ] sample_grammars..... Sample Grammars\n","  [ ] semcor.............. SemCor 3.0\n","Hit Enter to continue: \n","  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n","  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n","  [ ] sentiwordnet........ SentiWordNet\n","  [ ] shakespeare......... Shakespeare XML Corpus Sample\n","  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n","  [ ] smultron............ SMULTRON Corpus Sample\n","  [ ] snowball_data....... Snowball Data\n","  [ ] spanish_grammars.... Grammars for Spanish\n","  [ ] state_union......... C-Span State of the Union Address Corpus\n","  [ ] subjectivity........ Subjectivity Dataset v1.0\n","  [ ] swadesh............. Swadesh Wordlists\n","  [ ] switchboard......... Switchboard Corpus Sample\n","  [ ] tagsets............. Help on Tagsets\n","  [ ] timit............... TIMIT Corpus Sample\n","  [ ] toolbox............. Toolbox Sample Files\n","  [ ] treebank............ Penn Treebank Sample\n","  [ ] twitter_samples..... Twitter Samples\n","  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n","                           (Unicode Version)\n","  [ ] udhr................ Universal Declaration of Human Rights Corpus\n","  [ ] unicode_samples..... Unicode Samples\n","Hit Enter to continue: \n","  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n","  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n","  [ ] vader_lexicon....... VADER Sentiment Lexicon\n","  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n","  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n","  [ ] webtext............. Web Text Corpus\n","  [ ] wmt15_eval.......... Evaluation data from WMT15\n","  [ ] word2vec_sample..... Word2Vec Sample\n","  [ ] wordnet............. WordNet\n","  [ ] wordnet_ic.......... WordNet-InfoContent\n","  [ ] words............... Word Lists\n","  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n","                           English Prose\n","\n","Collections:\n","  [P] all-corpora......... All the corpora\n","  [P] all-nltk............ All packages available on nltk_data gh-pages\n","                           branch\n","  [P] all................. All packages\n","  [P] book................ Everything used in the NLTK Book\n","  [P] popular............. Popular packages\n","  [ ] tests............... Packages for running tests\n","Hit Enter to continue: \n","  [ ] third-party......... Third-party data packages\n","\n","([*] marks installed packages; [P] marks partially installed collections)\n","\n","Download which package (l=list; x=cancel)?\n","  Identifier> l\n","Packages:\n","  [ ] abc................. Australian Broadcasting Commission 2006\n","  [ ] alpino.............. Alpino Dutch Treebank\n","  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n","  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n","  [ ] basque_grammars..... Grammars for Basque\n","  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n","                           Extraction Systems in Biology)\n","  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n","  [ ] book_grammars....... Grammars from NLTK Book\n","  [ ] brown............... Brown Corpus\n","  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n","  [ ] cess_cat............ CESS-CAT Treebank\n","  [ ] cess_esp............ CESS-ESP Treebank\n","  [ ] chat80.............. Chat-80 Data Files\n","  [ ] city_database....... City Database\n","  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n","  [ ] comparative_sentences Comparative Sentence Dataset\n","  [ ] comtrans............ ComTrans Corpus Sample\n","  [ ] conll2000........... CONLL 2000 Chunking Corpus\n","  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n","Hit Enter to continue: \n","  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n","                           and Basque Subset)\n","  [ ] crubadan............ Crubadan Corpus\n","  [ ] dependency_treebank. Dependency Parsed Treebank\n","  [ ] dolch............... Dolch Word List\n","  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n","                           Corpus\n","  [ ] floresta............ Portuguese Treebank\n","  [ ] framenet_v15........ FrameNet 1.5\n","  [ ] framenet_v17........ FrameNet 1.7\n","  [ ] gazetteers.......... Gazeteer Lists\n","  [ ] genesis............. Genesis Corpus\n","  [ ] gutenberg........... Project Gutenberg Selections\n","  [ ] ieer................ NIST IE-ER DATA SAMPLE\n","  [ ] inaugural........... C-Span Inaugural Address Corpus\n","  [ ] indian.............. Indian Language POS-Tagged Corpus\n","  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n","                           ChaSen format)\n","  [ ] kimmo............... PC-KIMMO Data Files\n","  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n","  [ ] large_grammars...... Large context-free and feature-based grammars\n","                           for parser comparison\n","Hit Enter to continue: \n","  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n","  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n","                           part-of-speech tags\n","  [ ] machado............. Machado de Assis -- Obra Completa\n","  [ ] masc_tagged......... MASC Tagged Corpus\n","  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n","  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n","  [ ] moses_sample........ Moses Sample Models\n","  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n","  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n","  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n","                           2015) subset of the Paraphrase Database.\n","  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n","  [ ] nombank.1.0......... NomBank Corpus 1.0\n","  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n","  [ ] nps_chat............ NPS Chat\n","  [ ] omw................. Open Multilingual Wordnet\n","  [ ] opinion_lexicon..... Opinion Lexicon\n","  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n","  [ ] paradigms........... Paradigm Corpus\n","  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n","                           Evaluation Shared Task\n","Hit Enter to continue: \n","  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n","                           character properties in Perl\n","  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n","  [ ] pl196x.............. Polish language of the XX century sixties\n","  [ ] porter_test......... Porter Stemmer Test Files\n","  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n","  [ ] problem_reports..... Problem Report Corpus\n","  [ ] product_reviews_1... Product Reviews (5 Products)\n","  [ ] product_reviews_2... Product Reviews (9 Products)\n","  [ ] propbank............ Proposition Bank Corpus 1.0\n","  [ ] pros_cons........... Pros and Cons\n","  [ ] ptb................. Penn Treebank\n","  [ ] punkt............... Punkt Tokenizer Models\n","  [ ] qc.................. Experimental Data for Question Classification\n","  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n","                           version\n","  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n","                           Portuguesa)\n","  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n","  [ ] sample_grammars..... Sample Grammars\n","  [ ] semcor.............. SemCor 3.0\n","Hit Enter to continue: \n","  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n","  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n","  [ ] sentiwordnet........ SentiWordNet\n","  [ ] shakespeare......... Shakespeare XML Corpus Sample\n","  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n","  [ ] smultron............ SMULTRON Corpus Sample\n","  [ ] snowball_data....... Snowball Data\n","  [ ] spanish_grammars.... Grammars for Spanish\n","  [ ] state_union......... C-Span State of the Union Address Corpus\n","  [ ] subjectivity........ Subjectivity Dataset v1.0\n","  [ ] swadesh............. Swadesh Wordlists\n","  [ ] switchboard......... Switchboard Corpus Sample\n","  [ ] tagsets............. Help on Tagsets\n","  [ ] timit............... TIMIT Corpus Sample\n","  [ ] toolbox............. Toolbox Sample Files\n","  [ ] treebank............ Penn Treebank Sample\n","  [ ] twitter_samples..... Twitter Samples\n","  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n","                           (Unicode Version)\n","  [ ] udhr................ Universal Declaration of Human Rights Corpus\n","  [ ] unicode_samples..... Unicode Samples\n","Hit Enter to continue: \n","  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n","  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n","  [ ] vader_lexicon....... VADER Sentiment Lexicon\n","  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n","  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n","  [ ] webtext............. Web Text Corpus\n","  [ ] wmt15_eval.......... Evaluation data from WMT15\n","  [ ] word2vec_sample..... Word2Vec Sample\n","  [ ] wordnet............. WordNet\n","  [ ] wordnet_ic.......... WordNet-InfoContent\n","  [ ] words............... Word Lists\n","  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n","                           English Prose\n","\n","Collections:\n","  [P] all-corpora......... All the corpora\n","  [P] all-nltk............ All packages available on nltk_data gh-pages\n","                           branch\n","  [P] all................. All packages\n","  [P] book................ Everything used in the NLTK Book\n","  [P] popular............. Popular packages\n","  [ ] tests............... Packages for running tests\n","Hit Enter to continue: \n","  [ ] third-party......... Third-party data packages\n","\n","([*] marks installed packages; [P] marks partially installed collections)\n","\n","Download which package (l=list; x=cancel)?\n","  Identifier> x\n","\n","---------------------------------------------------------------------------\n","    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n","---------------------------------------------------------------------------\n","Downloader> q\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"sF96bw0sU0Nd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"1cb28af7-8fef-4ece-b473-22e493e267c4","executionInfo":{"status":"ok","timestamp":1580620817999,"user_tz":-330,"elapsed":1601,"user":{"displayName":"chandra mohan rawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDutMpxlwi1FVhJZFlXcFNeM_4jIhRg2u8JTdcOgQ=s64","userId":"11308919128317599349"}}},"source":["nltk.download('stopwords')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"2Y2ADZchU8ue","colab_type":"code","colab":{}},"source":["from nltk.corpus import stopwords"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UYH9zcGcWMq6","colab_type":"code","colab":{}},"source":["from nltk.stem import PorterStemmer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JSXwHef3WaGk","colab_type":"code","colab":{}},"source":["ps=PorterStemmer()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xeqfzWSwWgtv","colab_type":"code","colab":{}},"source":["corpus=[]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TfpFH1ZlWjkG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1f1290a7-3988-4d27-a03c-be7635124400","executionInfo":{"status":"ok","timestamp":1580625887805,"user_tz":-330,"elapsed":2547,"user":{"displayName":"chandra mohan rawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDutMpxlwi1FVhJZFlXcFNeM_4jIhRg2u8JTdcOgQ=s64","userId":"11308919128317599349"}}},"source":["ps"],"execution_count":159,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<PorterStemmer>"]},"metadata":{"tags":[]},"execution_count":159}]},{"cell_type":"code","metadata":{"id":"LoL_LTRkWpfD","colab_type":"code","colab":{}},"source":["for i in range(len(mail)):\n","  review=re.sub('[^a-zA-Z]','',mail['message'][i])\n","  review=review.lower()\n","  review=review.split()\n","  review=[ps.stem(word) for word in review if not word in stopwords.words('english')]\n","  review=''.join(review)\n","  corpus.append(review)    \n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sqrkaz8IdWRq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"outputId":"1806de28-6c30-4e2a-924c-5febe2bb7f66","executionInfo":{"status":"ok","timestamp":1580625902060,"user_tz":-330,"elapsed":7174,"user":{"displayName":"chandra mohan rawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDutMpxlwi1FVhJZFlXcFNeM_4jIhRg2u8JTdcOgQ=s64","userId":"11308919128317599349"}}},"source":["pip install -U scikit-learn"],"execution_count":161,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.1)\n","Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n","Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"evCgfRlXXCmd","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import TfidfVectorizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LkkV5DmIaflI","colab_type":"code","colab":{}},"source":["cv=TfidfVectorizer(max_features=5000)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_m51lzzZf-CP","colab_type":"code","colab":{}},"source":["X=cv.fit_transform(corpus).toarray()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rw4LvXzzf-4i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"b2163b51-a6cf-42c2-fa5e-1730e214ca51","executionInfo":{"status":"ok","timestamp":1580625909027,"user_tz":-330,"elapsed":913,"user":{"displayName":"chandra mohan rawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDutMpxlwi1FVhJZFlXcFNeM_4jIhRg2u8JTdcOgQ=s64","userId":"11308919128317599349"}}},"source":["X.shape"],"execution_count":165,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5572, 5000)"]},"metadata":{"tags":[]},"execution_count":165}]},{"cell_type":"code","metadata":{"id":"SqpSKwclgSbx","colab_type":"code","colab":{}},"source":["y=pd.get_dummies(mail['label'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nN-mtADGhFXF","colab_type":"code","colab":{}},"source":["y=y.iloc[:,1].values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m0fE__rKhGG6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"2dfae198-f085-4028-8bea-8c8d3f368404","executionInfo":{"status":"ok","timestamp":1580625920711,"user_tz":-330,"elapsed":1544,"user":{"displayName":"chandra mohan rawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDutMpxlwi1FVhJZFlXcFNeM_4jIhRg2u8JTdcOgQ=s64","userId":"11308919128317599349"}}},"source":["y.shape"],"execution_count":168,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5572,)"]},"metadata":{"tags":[]},"execution_count":168}]},{"cell_type":"code","metadata":{"id":"A6WXt3pVhaLM","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_qeHQiiiEhJ","colab_type":"code","colab":{}},"source":["from sklearn.naive_bayes import MultinomialNB\n","spam_detect_model=MultinomialNB().fit(X_train,y_train)\n","y_pred=spam_detect_model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YACIX0ivi710","colab_type":"code","colab":{}},"source":["from sklearn.metrics import confusion_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gp27HaXEj71j","colab_type":"code","colab":{}},"source":["confusion_m=confusion_matrix(y_test,y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zl6rGAiEk1ZF","colab_type":"code","colab":{}},"source":["from sklearn.metrics import accuracy_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ot1m0jb8k-8S","colab_type":"code","colab":{}},"source":["accuracy=accuracy_score(y_test,y_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qq7C05Wnl2Hm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"b90d4946-9cd8-40b1-b2a4-e2eda008514f","executionInfo":{"status":"ok","timestamp":1580625935925,"user_tz":-330,"elapsed":1565,"user":{"displayName":"chandra mohan rawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDutMpxlwi1FVhJZFlXcFNeM_4jIhRg2u8JTdcOgQ=s64","userId":"11308919128317599349"}}},"source":["confusion_m"],"execution_count":175,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[955,   0],\n","       [156,   4]])"]},"metadata":{"tags":[]},"execution_count":175}]},{"cell_type":"code","metadata":{"id":"8M9PM9YjlFmg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"8140f646-d47c-420c-a036-9a82934e4eaf","executionInfo":{"status":"ok","timestamp":1580625939030,"user_tz":-330,"elapsed":1467,"user":{"displayName":"chandra mohan rawat","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mDutMpxlwi1FVhJZFlXcFNeM_4jIhRg2u8JTdcOgQ=s64","userId":"11308919128317599349"}}},"source":["accuracy"],"execution_count":176,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8600896860986547"]},"metadata":{"tags":[]},"execution_count":176}]},{"cell_type":"code","metadata":{"id":"uX49IbWglJNv","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}